---
layout: default
title: "Portfolio of Milorad Spasić"
---
# Welcome to the Portfolio of Milorad Spasić

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Certifications](#certifications) &nbsp; &nbsp;[Contact](#contact)

## Data Engineer & Database Architect

A seasoned Data Engineer, DevOps Engineer, and Database Architect with two decades of experience in designing, optimizing, and managing high-performance data systems. The focus is on developing reliable data pipelines, architecting scalable and resilient databases, and deploying cloud-native solutions to enable real-time analytics and enterprise-level data processing.

### Core Expertise

- **Data Engineering & Architecture:**  
  Proficiency in Python and SQL, with extensive experience in ETL/ELT frameworks including Debezium, Kafka, Greenplum, and Hadoop, enabling robust real-time data streaming and analytics.

- **Database Administration & Optimization:**  
  Over 20 years of experience managing SQL Server, PostgreSQL, and distributed databases, with deep expertise in query optimization, high availability configurations, and disaster recovery strategies.

- **DevOps & Cloud Solutions:**  
  Expertise in Docker, Kubernetes, Terraform, Ansible, and cloud platforms such as AWS and GCP. Skilled in implementing infrastructure as code (IaC) and building efficient CI/CD pipelines.

- **Microservices & Automation:**  
  Development of containerized, event-driven microservices and adoption of GitOps workflows for building scalable and resilient data platforms.

- **Performance & Security:**  
  Advanced knowledge of indexing techniques, data partitioning, replication, and compliance with regulatory standards such as GDPR and HIPAA.

### Professional Impact

- Designed and implemented real-time analytics platforms capable of processing millions of events daily using technologies like Kafka, Python, and Kubernetes.  
- Optimized high-throughput transactional databases for enterprise clients, achieving up to 60% reduction in query execution times and improved system resilience.  
- Led seamless migrations from Microsoft SQL Server to PostgreSQL, ensuring minimal downtime and data integrity throughout the transition.  
- Architected cloud-based data solutions that enhanced scalability, operational efficiency, and cost-effectiveness.

This portfolio reflects a results-oriented engineering approach focused on data-driven innovation, cloud transformation, and automation—bridging the gap between data, DevOps, and engineering excellence.

---

# Skills

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Certifications](#certifications) &nbsp; &nbsp;[Contact](#contact)

## Technical Skills

- **Data Integration Tools:**  
  Debezium, Kafka  

- **Databases:**  
  Microsoft SQL Server, MySQL, Oracle, PostgreSQL, Vertica, Greenplum  

- **Programming Languages:**  
  Python (data processing and pipeline orchestration), Bash  

- **Containerization & Orchestration:**  
  Docker, Kubernetes  

- **CI/CD and Infrastructure as Code:**  
  GitHub Actions, Ansible, Terraform, Pulumi  

- **Monitoring & Logging:**  
  Prometheus, Grafana, Graylog  

- **Data Architecture:**  
  Event-driven architecture, Microservices, Real-time data processing pipelines  

## Data Engineer

10+ years of experience in data engineering, with a strong emphasis on building robust data pipelines using Python for automation and scripting, combined with advanced SQL skills for querying, optimizing, and managing relational databases.
Designing and implementing modern data architectures, with a strong focus on scalability, performance, and availability. This includes expertise in key architectural components such as cloud storage, distributed computing frameworks, and streaming or batch data processing pipelines to enable robust, flexible, and efficient data solutions.

## Database architect and database engineer/developer 

25+ years of experience in Administrating and working mostly on highly transactional relational databases (SQL Server, PostgreSQL).
- Proficiency in ETL/ELT data pipeline with Debezium and Kafka to analytic databases Greenplum, Vertica, Hadoop.
- Proficiency programming in Python.

## DevOps Engineer

- Proficiency with containerization and orchestration technologies such as **Docker** and **Kubernetes**.
- Experience working with **Helm**.
- Experience working with cloud **AWS**, **GCP**.
- Proficiency with configuration management tools like **Ansible** and **Terraform**.
- Understanding of **CI/CD** principles and **GitOps* practices.
- Proficiency in administering databases like **PostgreSQL**, **MS SQL**.
- Experience with network protocols (TCP, IP, UDP), and routing protocols.
- Proficiency in programming in **Python** and scripting in **Bash**.
- Proficiency in **Linux**.

## Database Management Systems (DBMS)

- Microsoft SQL Server (2000 - Latest Version)
- PostgreSQL (9.6 - Latest Version)

## Database Development & Optimization

- Complex stored procedures, functions, triggers, and views
- Advanced indexing strategies (Clustered, Non-Clustered, Full-Text, JSON/GIN Indexes)
- Query tuning and optimization (Execution Plans, Query Store, Hints, Statistics)
- Partitioning strategies for large datasets
- Columnstore and in-memory OLTP optimization

## Database Programming & Query Languages

- **T-SQL** (Microsoft SQL Server)
- **PL/SQL** (Oracle)
- **PL/PGSQL** (PostgreSQL)

## High Availability & Disaster Recovery

- Always On Availability Groups (SQL Server)
- Log shipping, database mirroring, and replication
- Failover Clustering (Windows and PostgreSQL)
- PITR (Point-in-Time Recovery) and WAL archiving (PostgreSQL)
- Backup strategies (Full, Differential, Incremental, PITR, Snapshots)

## Security & Compliance

- Role-based access control (RBAC) and fine-grained permissions
- Transparent Data Encryption (TDE) and row-level security
- Dynamic Data Masking & Always Encrypted (SQL Server)
- Data auditing, GDPR 
- Secure database configurations and vulnerability assessments

## ETL & Data Integration

- SQL Server Integration Services (SSIS)
- PostgreSQL Foreign Data Wrappers (FDW)
- Data migration & transformation (ETL pipelines, CDC, bulk inserts)
- JSON, XML, and CSV data handling

## Infrastructure & Automation

- Scripting automation with Python and Bash
- Database infrastructure as code (IaC) using Terraform
- Containerization with Docker for PostgreSQL
- Cloud database management (Azure SQL, Amazon RDS, Google Cloud SQL)
- Database monitoring with Prometheus, Grafana, and SQL Server Profiler

----

## Certifications

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Certifications](#certifications) &nbsp; &nbsp;[Contact](#contact)

- HP ASE – Vertica Big Data Solutions Administrator  
- Pivotal Greenplum Database Administrator  
- Pivotal Greenplum Database Developer  
- Microsoft Certified Solutions Expert in Data Management and Analytics  

---

# Projects

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Certifications](#certifications) &nbsp; &nbsp;[Contact](#contact)

## Project Highlights

### Real-Time Analytics Platform

- **Objective:**  
  Developed a real-time analytics platform to process and analyze data for business intelligence applications.

- **Technologies Used:**  
  Debezium, Kafka, Python, Greenplum, Docker, Kubernetes, Graylog, Prometheus, Grafana

- **Key Achievements:**  
  - Achieved sub-second latency in capturing and processing database changes  
  - Designed and implemented scalable microservices capable of handling millions of events daily  
  - Built Grafana dashboards to monitor system performance and critical operational metrics  

### Microservices-Based Data Pipeline

- **Objective:**  
  Developed a microservices-based architecture to enable real-time streaming and processing of large datasets from multiple relational databases.

- **Technologies Used:**  
  Debezium, Kafka, Python, Docker, Kubernetes

- **Key Achievements:**  
  - Automated deployment and scaling of services using Kubernetes  
  - Reduced operational complexity by centralizing logs through Graylog containers  
  - Improved fault tolerance via Kafka partitioning and replication strategies  

### GPS Tracking & Telemetry Data Pipeline

- Designed and maintained high-performance, real-time data pipelines focused on GPS tracking systems and telemetry data ingestion.  
- Engineered solutions capable of processing hundreds of millions of records per day to support real-time analytics.  
- Leveraged cloud infrastructure, containerization, and data streaming technologies to optimize workflows for high-velocity, high-volume environments.  

---

# Experience

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Certifications](#certifications) &nbsp; &nbsp;[Contact](#contact)

## Professional Experience

### 1. Database Change Data Capture (CDC) with Debezium

- Implemented Change Data Capture (CDC) pipelines using Debezium to capture real-time changes from relational databases such as Microsoft SQL Server, MySQL, Oracle, and PostgreSQL.  
- Configured Debezium connectors to ensure minimal latency and high reliability in data streaming processes.  

### 2. Data Streaming with Kafka

- Designed and managed Kafka topics to support high-throughput, real-time data ingestion.  
- Ensured data consistency and fault tolerance through the implementation of robust Kafka configurations.  

### 3. Data Processing and Loading

- Developed Python-based consumers for processing Kafka streams and loading enriched data into the Greenplum analytical database.  
- Applied transformation and enrichment logic to prepare data for analytical use cases.  

### 4. Microservices Architecture

- Designed and developed modular, scalable microservices for data ingestion, transformation, and delivery.  
- Deployed microservices within a containerized environment using Docker.  
- Orchestrated containers with Kubernetes to maintain high availability and scalability of data workflows.  

### 5. Logging and Monitoring

- Centralized application logging using Logstash containers to enable real-time log tracking and diagnostics.  
- Monitored system health and performance metrics via Prometheus, with dashboards and visualizations created in Grafana.  

### 6. Data Analytics Pipeline

- Designed and optimized end-to-end pipelines capable of handling high-volume, real-time analytical workloads.  
- Ensured seamless integration between source systems, streaming platforms, and the Greenplum analytical database.

---

# Contact

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Certifications](#certifications) &nbsp; &nbsp;[Contact](#contact)

  - email: [Milorad Spasic](mailto:milorad.spasic@datameshsync.info)
  - Linkedin: [Linkedin](https://www.linkedin.com/in/milorad-spasic)
