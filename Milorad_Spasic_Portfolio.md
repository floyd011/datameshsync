# Welcome to the Portfolio of Milorad Spasić

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Contact](#contact)

## Data Engineer & Database Architect

A seasoned Data Engineer, DevOps Engineer, and Database Architect with two decades of experience in designing, optimizing, and managing high-performance data systems. The focus is on developing reliable data pipelines, architecting scalable and resilient databases, and deploying cloud-native solutions to enable real-time analytics and enterprise-level data processing.

### Core Expertise

- **Data Engineering & Architecture:**  
  Proficiency in Python and SQL, with extensive experience in ETL/ELT frameworks including Debezium, Kafka, Greenplum, and Hadoop, enabling robust real-time data streaming and analytics.

- **Database Administration & Optimization:**  
  Over 20 years of experience managing SQL Server, PostgreSQL, and distributed databases, with deep expertise in query optimization, high availability configurations, and disaster recovery strategies.

- **DevOps & Cloud Solutions:**  
  Expertise in Docker, Kubernetes, Terraform, Ansible, and cloud platforms such as AWS and GCP. Skilled in implementing infrastructure as code (IaC) and building efficient CI/CD pipelines.

- **Microservices & Automation:**  
  Development of containerized, event-driven microservices and adoption of GitOps workflows for building scalable and resilient data platforms.

- **Performance & Security:**  
  Advanced knowledge of indexing techniques, data partitioning, replication, and compliance with regulatory standards such as GDPR and HIPAA.

### Professional Impact

- Designed and implemented real-time analytics platforms capable of processing millions of events daily using technologies like Kafka, Python, and Kubernetes.  
- Optimized high-throughput transactional databases for enterprise clients, achieving up to 60% reduction in query execution times and improved system resilience.  
- Led seamless migrations from Microsoft SQL Server to PostgreSQL, ensuring minimal downtime and data integrity throughout the transition.  
- Architected cloud-based data solutions that enhanced scalability, operational efficiency, and cost-effectiveness.

This portfolio reflects a results-oriented engineering approach focused on data-driven innovation, cloud transformation, and automation—bridging the gap between data, DevOps, and engineering excellence.

---

# Skills

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Contact](#contact)

## Technical Skills

- **Data Integration Tools:**  
  Debezium, Kafka  

- **Databases:**  
  Microsoft SQL Server, MySQL, Oracle, PostgreSQL, Vertica, Greenplum  

- **Programming Languages:**  
  Python (data processing and pipeline orchestration), Bash  

- **Containerization & Orchestration:**  
  Docker, Kubernetes  

- **CI/CD and Infrastructure as Code:**  
  GitHub Actions, Ansible, Terraform, Pulumi  

- **Monitoring & Logging:**  
  Prometheus, Grafana, Graylog  

- **Data Architecture:**  
  Event-driven architecture, Microservices, Real-time data processing pipelines  

## Certifications

- HP ASE – Vertica Big Data Solutions Administrator  
- Pivotal Greenplum Database Administrator  
- Pivotal Greenplum Database Developer  
- Microsoft Certified Solutions Expert in Data Management and Analytics  

---

# Projects

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Contact](#contact)

## Project Highlights

### Real-Time Analytics Platform

- **Objective:**  
  Developed a real-time analytics platform to process and analyze data for business intelligence applications.

- **Technologies Used:**  
  Debezium, Kafka, Python, Greenplum, Docker, Kubernetes, Graylog, Prometheus, Grafana

- **Key Achievements:**  
  - Achieved sub-second latency in capturing and processing database changes  
  - Designed and implemented scalable microservices capable of handling millions of events daily  
  - Built Grafana dashboards to monitor system performance and critical operational metrics  

### Microservices-Based Data Pipeline

- **Objective:**  
  Developed a microservices-based architecture to enable real-time streaming and processing of large datasets from multiple relational databases.

- **Technologies Used:**  
  Debezium, Kafka, Python, Docker, Kubernetes

- **Key Achievements:**  
  - Automated deployment and scaling of services using Kubernetes  
  - Reduced operational complexity by centralizing logs through Graylog containers  
  - Improved fault tolerance via Kafka partitioning and replication strategies  

### GPS Tracking & Telemetry Data Pipeline

- Designed and maintained high-performance, real-time data pipelines focused on GPS tracking systems and telemetry data ingestion.  
- Engineered solutions capable of processing hundreds of millions of records per day to support real-time analytics.  
- Leveraged cloud infrastructure, containerization, and data streaming technologies to optimize workflows for high-velocity, high-volume environments.  

---

# Experience

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Contact](#contact)

## Professional Experience

### 1. Database Change Data Capture (CDC) with Debezium

- Implemented Change Data Capture (CDC) pipelines using Debezium to capture real-time changes from relational databases such as Microsoft SQL Server, MySQL, Oracle, and PostgreSQL.  
- Configured Debezium connectors to ensure minimal latency and high reliability in data streaming processes.  

### 2. Data Streaming with Kafka

- Designed and managed Kafka topics to support high-throughput, real-time data ingestion.  
- Ensured data consistency and fault tolerance through the implementation of robust Kafka configurations.  

### 3. Data Processing and Loading

- Developed Python-based consumers for processing Kafka streams and loading enriched data into the Greenplum analytical database.  
- Applied transformation and enrichment logic to prepare data for analytical use cases.  

### 4. Microservices Architecture

- Designed and developed modular, scalable microservices for data ingestion, transformation, and delivery.  
- Deployed microservices within a containerized environment using Docker.  
- Orchestrated containers with Kubernetes to maintain high availability and scalability of data workflows.  

### 5. Logging and Monitoring

- Centralized application logging using Logstash containers to enable real-time log tracking and diagnostics.  
- Monitored system health and performance metrics via Prometheus, with dashboards and visualizations created in Grafana.  

### 6. Data Analytics Pipeline

- Designed and optimized end-to-end pipelines capable of handling high-volume, real-time analytical workloads.  
- Ensured seamless integration between source systems, streaming platforms, and the Greenplum analytical database.

---

# Contact

[Home](#welcome-to-the-portfolio-of-milorad-spasić) &nbsp; &nbsp; [Skills](#skills) &nbsp; &nbsp;[Projects](#projects) &nbsp; &nbsp;[Experience](#experience) &nbsp; &nbsp;[Contact](#contact)

  - email: [Milorad Spasic](mailto:milorad.spasic@datameshsync.info)
  - Linkedin: [Linkedin](https://www.linkedin.com/in/milorad-spasic)
